{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9c835be-9142-43ba-bd31-0bc3ac9fcbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.safetensors     2025-04-27 01:24:13.947944\n",
      "tokenizer_config.json  2025-04-27 01:24:13.962625\n",
      "special_tokens_map.json  2025-04-27 01:24:13.962734\n",
      "config.json           2025-04-27 01:24:13.716560\n",
      "training_args.bin     2025-04-27 01:24:13.961356\n",
      "vocab.txt             2025-04-27 01:24:13.968700\n",
      "Cleaned input saved to: ../inferred_inputs/input_to_predict_20250427_025122.csv\n",
      "Inference results saved to: ../inferred_outputs/predictedoutput_20250427_025122.csv\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime           \n",
    "from sqlalchemy import create_engine\n",
    "from urllib.parse import quote_plus\n",
    "import os\n",
    "import glob\n",
    "# -----------------------------\n",
    "# Load the model and tokenizer\n",
    "# -----------------------------\n",
    "model_path = \"./results/final_model\"\n",
    "for f in glob.glob(f\"{model_path}/*\"):\n",
    "    t = datetime.fromtimestamp(os.path.getmtime(f))\n",
    "    print(f\"{os.path.basename(f):20s}  {t}\")\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# -----------------------------\n",
    "# Connect to the database (NEVER STORE CREDS IN A SCRIPT)\n",
    "# -----------------------------\n",
    "db_type = 'postgresql'\n",
    "host = 'localhost'\n",
    "dbname = 'Qrious'\n",
    "user = 'postgres'\n",
    "password = quote_plus('Postgres@qrious')\n",
    "port = '5432'\n",
    "\n",
    "conn_str = f'{db_type}://{user}:{password}@{host}:{port}/{dbname}'\n",
    "engine = create_engine(conn_str)\n",
    "\n",
    "# query = \"\"\"\n",
    "#     SELECT DISTINCT product_name_raw\n",
    "#     FROM cleaned_retailer_events\n",
    "#     WHERE relevant_code_binary IS NULL\n",
    "#     LIMIT 10000\n",
    "# \"\"\"\n",
    "\n",
    "#df = pd.read_sql(query, engine)\n",
    "df = df_split = pd.read_csv(\"/Users/ramana/Documents/shopper_analysis/inferred_inputs/InputForInference_202504270250.csv\")\n",
    "\n",
    "# -----------------------------\n",
    "# Clean the product names\n",
    "# -----------------------------\n",
    "def clean_product_name(text):\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z0-9\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "# Drop missing or empty values\n",
    "df = df.dropna(subset=[\"product_name_raw\"])\n",
    "df[\"product_name_raw\"] = df[\"product_name_raw\"].astype(str).str.strip()\n",
    "df = df[df[\"product_name_raw\"] != \"\"]\n",
    "\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates(subset=[\"product_name_raw\"])\n",
    "\n",
    "# Apply cleaning\n",
    "df[\"cleaned_product_name\"] = df[\"product_name_raw\"].apply(clean_product_name)\n",
    "\n",
    "df.head()\n",
    "\n",
    "# -----------------------------\n",
    "# Save cleaned input\n",
    "# -----------------------------\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "os.makedirs(\"../inferred_inputs\", exist_ok=True)\n",
    "cleaned_path = f\"../inferred_inputs/input_to_predict_{timestamp}.csv\"\n",
    "df[[\"product_name_raw\", \"cleaned_product_name\"]].to_csv(cleaned_path, index=False)\n",
    "print(f\"Cleaned input saved to: {cleaned_path}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Inference\n",
    "# -----------------------------\n",
    "def predict_label(text):\n",
    "    encoded = tokenizer(\n",
    "        text,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=64,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    input_ids = encoded[\"input_ids\"].to(device)\n",
    "    attention_mask = encoded[\"attention_mask\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = output.logits\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        pred_label = torch.argmax(probs, dim=1).item()\n",
    "        confidence = probs[0][pred_label].item()\n",
    "    return pred_label, confidence, probs.tolist()[0]\n",
    "\n",
    "# Run predictions\n",
    "predictions = []\n",
    "for name in df[\"cleaned_product_name\"]:\n",
    "    label, conf, probs = predict_label(name)\n",
    "    predictions.append((label, conf, probs))\n",
    "\n",
    "df[\"predicted_label\"] = [p[0] for p in predictions]\n",
    "df[\"confidence\"] = [p[1] for p in predictions]\n",
    "df[\"prob_nonfashion\"] = [p[2][0] for p in predictions]\n",
    "df[\"prob_fashion\"] = [p[2][1] for p in predictions]\n",
    "\n",
    "# -----------------------------\n",
    "# Save output\n",
    "# -----------------------------\n",
    "os.makedirs(\"../inferred_outputs\", exist_ok=True)\n",
    "inferred_path = f\"../inferred_outputs/predictedoutput_{timestamp}.csv\"\n",
    "df.to_csv(inferred_path, index=False)\n",
    "print(f\"Inference results saved to: {inferred_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da56d2cd-6aaa-46be-a9f6-8376b857baf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bert_env)",
   "language": "python",
   "name": "bert_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
