{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "422c02ed-9d4a-45fe-8adf-cefaff045dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "467c9ef1-8856-4e8d-98b0-e1d46f3a9171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlalchemy in /Users/ramana/anaconda3/lib/python3.12/site-packages (2.0.37)\n",
      "Requirement already satisfied: psycopg2-binary in /Users/ramana/anaconda3/lib/python3.12/site-packages (2.9.10)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from sqlalchemy) (4.13.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sqlalchemy psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "618da677-89a2-4a07-b977-d989800fd4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   test_connection\n",
      "0                1\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "# Connection parameters\n",
    "db_type = 'postgresql'\n",
    "host = 'localhost'\n",
    "dbname = 'Qrious'\n",
    "user = 'postgres'\n",
    "password = quote_plus('Postgres@qrious')  # safely escape @ symbol\n",
    "port = '5432'\n",
    "\n",
    "# Build connection string\n",
    "conn_str = f'{db_type}://{user}:{password}@{host}:{port}/{dbname}'\n",
    "\n",
    "# Create engine\n",
    "engine = create_engine(conn_str)\n",
    "\n",
    "# Test connection\n",
    "with engine.connect() as conn:\n",
    "    df_test = pd.read_sql(\"SELECT 1 AS test_connection\", conn)\n",
    "\n",
    "print(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c7c186a-ac26-41a0-898a-364337527152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows pulled: 187413\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name_raw</th>\n",
       "      <th>relevant_code_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Disney Girls' Toddler Minnie Seven Pack Brief ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hanes Women's Comfort Fit No Show Socks 10-pack</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hanes Women's French Terry Pocket Capri</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hanes Women's Perfect-T Short Sleeve T-Shirt, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Disney Girls' Toddler Minnie Seven Pack Brief ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    product_name_raw  relevant_code_binary\n",
       "0  Disney Girls' Toddler Minnie Seven Pack Brief ...                     1\n",
       "1    Hanes Women's Comfort Fit No Show Socks 10-pack                     1\n",
       "2            Hanes Women's French Terry Pocket Capri                     1\n",
       "3  Hanes Women's Perfect-T Short Sleeve T-Shirt, ...                     1\n",
       "4  Disney Girls' Toddler Minnie Seven Pack Brief ...                     1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "    product_name_raw,\n",
    "    relevant_code_binary\n",
    "FROM cleaned_retailer_events\n",
    "WHERE relevant_code_binary IS NOT NULL\n",
    "\"\"\"\n",
    "df_labeled = pd.read_sql(query, engine)\n",
    "\n",
    "# Quick check\n",
    "print(f\"Total rows pulled: {len(df_labeled)}\")\n",
    "df_labeled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "baddd1d4-c78f-4925-9950-5ee59576c2cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name_raw</th>\n",
       "      <th>relevant_code_binary</th>\n",
       "      <th>cleaned_product_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Disney Girls' Toddler Minnie Seven Pack Brief ...</td>\n",
       "      <td>1</td>\n",
       "      <td>disney girls toddler minnie seven pack brief u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hanes Women's Comfort Fit No Show Socks 10-pack</td>\n",
       "      <td>1</td>\n",
       "      <td>hanes women s comfort fit no show socks 10 pack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hanes Women's French Terry Pocket Capri</td>\n",
       "      <td>1</td>\n",
       "      <td>hanes women s french terry pocket capri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hanes Women's Perfect-T Short Sleeve T-Shirt, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>hanes women s perfect t short sleeve t shirt l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ICOSY Girls Nightgowns Unicorn Dress Pajamas f...</td>\n",
       "      <td>1</td>\n",
       "      <td>icosy girls nightgowns unicorn dress pajamas f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    product_name_raw  relevant_code_binary  \\\n",
       "0  Disney Girls' Toddler Minnie Seven Pack Brief ...                     1   \n",
       "1    Hanes Women's Comfort Fit No Show Socks 10-pack                     1   \n",
       "2            Hanes Women's French Terry Pocket Capri                     1   \n",
       "3  Hanes Women's Perfect-T Short Sleeve T-Shirt, ...                     1   \n",
       "8  ICOSY Girls Nightgowns Unicorn Dress Pajamas f...                     1   \n",
       "\n",
       "                                cleaned_product_name  \n",
       "0  disney girls toddler minnie seven pack brief u...  \n",
       "1    hanes women s comfort fit no show socks 10 pack  \n",
       "2            hanes women s french terry pocket capri  \n",
       "3  hanes women s perfect t short sleeve t shirt l...  \n",
       "8  icosy girls nightgowns unicorn dress pajamas f...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Drop null product names (if any)\n",
    "df_labeled = df_labeled.dropna(subset=['product_name_raw'])\n",
    "\n",
    "# Drop exact duplicates\n",
    "df_labeled = df_labeled.drop_duplicates(subset=['product_name_raw', 'relevant_code_binary'])\n",
    "\n",
    "# Define a cleaning function\n",
    "def clean_product_name(text):\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z0-9\\s]\", \" \", text)  # keep letters, numbers, space\n",
    "    text = re.sub(r\"\\s+\", \" \", text)  # collapse multiple spaces\n",
    "    return text.strip()\n",
    "\n",
    "# Apply cleaning\n",
    "df_labeled['cleaned_product_name'] = df_labeled['product_name_raw'].apply(clean_product_name)\n",
    "\n",
    "# Drop rows where cleaned name ends up empty (just in case)\n",
    "df_labeled = df_labeled[df_labeled['cleaned_product_name'] != \"\"]\n",
    "\n",
    "# Show a sample\n",
    "df_labeled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc5a79b3-2fb9-486c-9203-2e7bc212a44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 13368\n",
      "Temp set (val + test): 3343\n",
      "Validation set: 1671\n",
      "Test set: 1672\n",
      "\n",
      "Split distribution:\n",
      "split_type\n",
      "train    13368\n",
      "test      1672\n",
      "val       1671\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label distribution by split (raw counts):\n",
      "split_type  relevant_code_binary\n",
      "test        1                        1382\n",
      "            0                         290\n",
      "train       1                       11048\n",
      "            0                        2320\n",
      "val         1                        1381\n",
      "            0                         290\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label distribution by split (percentages):\n",
      "split_type  relevant_code_binary\n",
      "test        1                       0.826555\n",
      "            0                       0.173445\n",
      "train       1                       0.826451\n",
      "            0                       0.173549\n",
      "val         1                       0.826451\n",
      "            0                       0.173549\n",
      "Name: percentage, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Make a safe copy of your cleaned and labeled data\n",
    "df = df_labeled.copy()\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Step 1: Split into 80% train and 20% temp (val+test)\n",
    "# Stratify ensures class distribution (0 vs 1) is preserved in both splits\n",
    "df_train, df_temp = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,  # 20% held out for val + test\n",
    "    stratify=df['relevant_code_binary'],\n",
    "    random_state=42  # for reproducibility\n",
    ")\n",
    "\n",
    "print(\"Train set:\", len(df_train))\n",
    "print(\"Temp set (val + test):\", len(df_temp))\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Step 2: Split temp into 50% val and 50% test\n",
    "df_val, df_test = train_test_split(\n",
    "    df_temp,\n",
    "    test_size=0.5,  # Half of temp becomes test (so test is 10% of total)\n",
    "    stratify=df_temp['relevant_code_binary'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Validation set:\", len(df_val))\n",
    "print(\"Test set:\", len(df_test))\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Step 3: Assign split labels to each set\n",
    "df_train['split_type'] = 'train'\n",
    "df_val['split_type'] = 'val'\n",
    "df_test['split_type'] = 'test'\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Step 4: Combine all splits back into a single dataframe\n",
    "df_split = pd.concat([df_train, df_val, df_test], axis=0).reset_index(drop=True)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Step 5: Check the split sizes\n",
    "print(\"\\nSplit distribution:\")\n",
    "print(df_split['split_type'].value_counts())\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Step 6: Check class balance in each split\n",
    "print(\"\\nLabel distribution by split (raw counts):\")\n",
    "print(df_split.groupby('split_type')['relevant_code_binary'].value_counts())\n",
    "\n",
    "print(\"\\nLabel distribution by split (percentages):\")\n",
    "percentages = df_split.groupby('split_type')['relevant_code_binary'].value_counts(normalize=True).rename(\"percentage\")\n",
    "print(percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd044906-30de-4933-8852-ec0542e3602f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Count labels within each split\n",
    "split_counts = df_split.groupby(['split_type', 'relevant_code_binary']).size().unstack()\n",
    "\n",
    "# Plot stacked bar chart\n",
    "split_counts.plot(kind='bar', stacked=True, figsize=(6, 4))\n",
    "plt.title(\"Label Distribution per Split\")\n",
    "plt.xlabel(\"Split Type\")\n",
    "plt.ylabel(\"Number of Records\")\n",
    "plt.legend(title='Label (1 = Fashion, 0 = Non-Fashion)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2480c8b7-b663-48f6-bade-a3924c97e705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "711"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_split.to_sql(\n",
    "    'fashion_labeled_cleaned',\n",
    "    engine,\n",
    "    if_exists='replace',  # Use 'replace' now since weâ€™ve just created and finalized this dataset\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b13a05e-ef55-4cd2-a751-5c6278047a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_split.to_csv(\"fashion_labeled_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0ffe675-5228-4cd0-95d3-f5d0235d7bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/ramana/anaconda3/lib/python3.12/site-packages (4.51.3)\n",
      "Requirement already satisfied: datasets in /Users/ramana/anaconda3/lib/python3.12/site-packages (3.5.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/ramana/anaconda3/lib/python3.12/site-packages (1.5.2)\n",
      "Requirement already satisfied: filelock in /Users/ramana/anaconda3/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/ramana/anaconda3/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/ramana/anaconda3/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /Users/ramana/anaconda3/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
      "  Using cached fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in /Users/ramana/anaconda3/lib/python3.12/site-packages (from datasets) (3.11.10)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.18.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Using cached fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "Installing collected packages: fsspec\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.2\n",
      "    Uninstalling fsspec-2025.3.2:\n",
      "      Successfully uninstalled fsspec-2025.3.2\n",
      "Successfully installed fsspec-2024.12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers datasets scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f52fc940-e558-4842-9655-326c67515dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: labakihah jeans for women women s mid waist lace up denim trousers stretch jeans flared pants bell bottom jeans for women light blue\n",
      "Input IDs: tensor([[  101,  6845,  8978,  3270,  2232,  6312,  2005,  2308,  2308,  1055,\n",
      "          3054,  5808, 12922,  2039, 26762, 15292,  7683,  6312, 14937,  6471,\n",
      "          4330,  3953,  6312,  2005,  2308,  2422,  2630,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the tokenizer for the BERT base model (uncased = lowercase)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize a sample to understand the format\n",
    "example = df_split['cleaned_product_name'].iloc[0]\n",
    "encoded = tokenizer(\n",
    "    example,\n",
    "    padding='max_length',       # pad to max_length\n",
    "    truncation=True,            # truncate if too long\n",
    "    max_length=64,              # max length of a product name\n",
    "    return_tensors='pt'         # return PyTorch tensors\n",
    ")\n",
    "\n",
    "print(\"Original Text:\", example)\n",
    "print(\"Input IDs:\", encoded['input_ids'])\n",
    "print(\"Attention Mask:\", encoded['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04641727-74e9-4227-93bd-f0ad5773d0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "035f4c5d684b473a85c6401f0815a2d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13368 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4fcb03beedd449b9ba0f89f0e60f8fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1671 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f07a6f3497b34a3a9825f3e90e1ff514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1672 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': tensor(1), 'input_ids': tensor([  101,  6845,  8978,  3270,  2232,  6312,  2005,  2308,  2308,  1055,\n",
      "         3054,  5808, 12922,  2039, 26762, 15292,  7683,  6312, 14937,  6471,\n",
      "         4330,  3953,  6312,  2005,  2308,  2422,  2630,   102,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# Step 1: Split DataFrame into 3 subsets\n",
    "train_df = df_split[df_split['split_type'] == 'train']\n",
    "val_df = df_split[df_split['split_type'] == 'val']\n",
    "test_df = df_split[df_split['split_type'] == 'test']\n",
    "\n",
    "# Step 2: Convert pandas DataFrames to Hugging Face Datasets\n",
    "dataset = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(train_df),\n",
    "    \"val\": Dataset.from_pandas(val_df),\n",
    "    \"test\": Dataset.from_pandas(test_df)\n",
    "})\n",
    "\n",
    "# Step 3: Tokenization function for all rows\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(\n",
    "        example[\"cleaned_product_name\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=64\n",
    "    )\n",
    "\n",
    "# Step 4: Apply tokenizer to each row in each split\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Step 5: Rename your label column to 'labels' (what BERT expects)\n",
    "tokenized_dataset = tokenized_dataset.rename_column(\"relevant_code_binary\", \"labels\")\n",
    "\n",
    "# Step 6: Set format to PyTorch\n",
    "tokenized_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "# Quick check\n",
    "print(tokenized_dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ecb72dac-7afd-4a1d-8319-01114d726f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: huggingface_hub[hf_xet]\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install huggingface_hub[hf_xet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d204043f-3fa1-42a9-a658-b0f12c2b7091",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSdpaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "# Load a pre-trained BERT model with a classification head on top\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels=2,     # Binary classification: 0 or 1\n",
    ")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed17e0b5-ef42-4963-a69f-0d6d232174cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
      "  Using cached huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy>=1.17 (from transformers)\n",
      "  Using cached numpy-2.2.5-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting packaging>=20.0 (from transformers)\n",
      "  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Using cached PyYAML-6.0.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2024.11.6-cp312-cp312-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting requests (from transformers)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Using cached tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.30.0->transformers)\n",
      "  Using cached fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub<1.0,>=0.30.0->transformers)\n",
      "  Using cached typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->transformers)\n",
      "  Using cached charset_normalizer-3.4.1-cp312-cp312-macosx_10_13_universal2.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->transformers)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
      "  Using cached urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Using cached transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "Using cached huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "Using cached numpy-2.2.5-cp312-cp312-macosx_14_0_arm64.whl (5.2 MB)\n",
      "Using cached packaging-25.0-py3-none-any.whl (66 kB)\n",
      "Using cached PyYAML-6.0.2-cp312-cp312-macosx_11_0_arm64.whl (173 kB)\n",
      "Using cached regex-2024.11.6-cp312-cp312-macosx_11_0_arm64.whl (284 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl (418 kB)\n",
      "Using cached tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp312-cp312-macosx_10_13_universal2.whl (196 kB)\n",
      "Using cached fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "Using cached urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Installing collected packages: urllib3, typing-extensions, tqdm, safetensors, regex, pyyaml, packaging, numpy, idna, fsspec, filelock, charset-normalizer, certifi, requests, huggingface-hub, tokenizers, transformers\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.4.0\n",
      "    Uninstalling urllib3-2.4.0:\n",
      "      Successfully uninstalled urllib3-2.4.0\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.13.2\n",
      "    Uninstalling typing_extensions-4.13.2:\n",
      "      Successfully uninstalled typing_extensions-4.13.2\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.67.1\n",
      "    Uninstalling tqdm-4.67.1:\n",
      "      Successfully uninstalled tqdm-4.67.1\n",
      "  Attempting uninstall: safetensors\n",
      "    Found existing installation: safetensors 0.5.3\n",
      "    Uninstalling safetensors-0.5.3:\n",
      "      Successfully uninstalled safetensors-0.5.3\n",
      "  Attempting uninstall: regex\n",
      "    Found existing installation: regex 2024.11.6\n",
      "    Uninstalling regex-2024.11.6:\n",
      "      Successfully uninstalled regex-2024.11.6\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 6.0.2\n",
      "    Uninstalling PyYAML-6.0.2:\n",
      "      Successfully uninstalled PyYAML-6.0.2\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 25.0\n",
      "    Uninstalling packaging-25.0:\n",
      "      Successfully uninstalled packaging-25.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.10\n",
      "    Uninstalling idna-3.10:\n",
      "      Successfully uninstalled idna-3.10\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.12.0\n",
      "    Uninstalling fsspec-2024.12.0:\n",
      "      Successfully uninstalled fsspec-2024.12.0\n",
      "  Attempting uninstall: filelock\n",
      "    Found existing installation: filelock 3.18.0\n",
      "    Uninstalling filelock-3.18.0:\n",
      "      Successfully uninstalled filelock-3.18.0\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 3.4.1\n",
      "    Uninstalling charset-normalizer-3.4.1:\n",
      "      Successfully uninstalled charset-normalizer-3.4.1\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2025.1.31\n",
      "    Uninstalling certifi-2025.1.31:\n",
      "      Successfully uninstalled certifi-2025.1.31\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.32.3\n",
      "    Uninstalling requests-2.32.3:\n",
      "      Successfully uninstalled requests-2.32.3\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.30.2\n",
      "    Uninstalling huggingface-hub-0.30.2:\n",
      "      Successfully uninstalled huggingface-hub-0.30.2\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.21.1\n",
      "    Uninstalling tokenizers-0.21.1:\n",
      "      Successfully uninstalled tokenizers-0.21.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.51.3\n",
      "    Uninstalling transformers-4.51.3:\n",
      "      Successfully uninstalled transformers-4.51.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 3.5.0 requires fsspec[http]<=2024.12.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.5 which is incompatible.\n",
      "streamlit 1.40.1 requires packaging<25,>=20, but you have packaging 25.0 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.5 which is incompatible.\n",
      "s3fs 2024.12.0 requires fsspec==2024.12.0.*, but you have fsspec 2025.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed certifi-2025.1.31 charset-normalizer-3.4.1 filelock-3.18.0 fsspec-2025.3.2 huggingface-hub-0.30.2 idna-3.10 numpy-2.2.5 packaging-25.0 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.3 safetensors-0.5.3 tokenizers-0.21.1 tqdm-4.67.1 transformers-4.51.3 typing-extensions-4.13.2 urllib3-2.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --force-reinstall transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6c21900-b188-4eda-9570-77fbc42e0825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.51.3\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dbdf5756-0bf2-43a8-9b75-f4e9345c2e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate>=0.26.0 in /Users/ramana/anaconda3/lib/python3.12/site-packages (1.6.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from accelerate>=0.26.0) (2.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from accelerate>=0.26.0) (25.0)\n",
      "Requirement already satisfied: psutil in /Users/ramana/anaconda3/lib/python3.12/site-packages (from accelerate>=0.26.0) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /Users/ramana/anaconda3/lib/python3.12/site-packages (from accelerate>=0.26.0) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from accelerate>=0.26.0) (2.5.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from accelerate>=0.26.0) (0.30.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from accelerate>=0.26.0) (0.5.3)\n",
      "Requirement already satisfied: filelock in /Users/ramana/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2025.3.2)\n",
      "Requirement already satisfied: requests in /Users/ramana/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.13.2)\n",
      "Requirement already satisfied: networkx in /Users/ramana/anaconda3/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /Users/ramana/anaconda3/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate>=0.26.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->accelerate>=0.26.0) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ramana/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install \"accelerate>=0.26.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0e8bc65-eb20-4e5a-b341-f7019906f644",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramana/anaconda3/envs/bert_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 38\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: acc,\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m: precision,\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m: recall,\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m: f1,\n\u001b[1;32m     34\u001b[0m     }\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Create the Trainer\u001b[39;00m\n\u001b[1;32m     37\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m---> 38\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m,\n\u001b[1;32m     39\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m     40\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtokenized_dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     41\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39mtokenized_dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     42\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m     43\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[EarlyStoppingCallback(early_stopping_patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)]  \u001b[38;5;66;03m# Stop if no val improvement for 2 evals\u001b[39;00m\n\u001b[1;32m     44\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',                # Where to save model and logs\n",
    "    eval_strategy='steps',                 # Evaluate more frequently to monitor overfitting\n",
    "    eval_steps=500,                        # Evaluate every 500 steps\n",
    "    save_strategy='steps',                 # Save model at the end of each epoch\n",
    "    save_total_limit=2,                    # Only keep last 2 models to save space\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,         \n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=10,                   # Train long, let early stopping cut off\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',                  # Log directory\n",
    "    logging_steps=50,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='accuracy',\n",
    "    greater_is_better=True\n",
    ")\n",
    "\n",
    "# Define evaluation metrics\n",
    "def compute_metrics(pred):\n",
    "    logits, labels = pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "    }\n",
    "\n",
    "# Create the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"val\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fdce1510-69fd-43c8-a07c-24b81e5730e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingArguments(\n",
      "_n_gpu=1,\n",
      "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "average_tokens_across_devices=False,\n",
      "batch_eval_metrics=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_prefetch_factor=None,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_do_concat_batches=True,\n",
      "eval_on_start=False,\n",
      "eval_steps=None,\n",
      "eval_strategy=IntervalStrategy.EPOCH,\n",
      "eval_use_gather_object=False,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=True,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_for_metrics=[],\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=True,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=./logs,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=50,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=accuracy,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3,\n",
      "optim=OptimizerNames.ADAMW_TORCH,\n",
      "optim_args=None,\n",
      "optim_target_modules=None,\n",
      "output_dir=./results,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=64,\n",
      "per_device_train_batch_size=16,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "restore_callback_states_from_checkpoint=False,\n",
      "resume_from_checkpoint=None,\n",
      "run_name=./results,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=500,\n",
      "save_strategy=SaveStrategy.EPOCH,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torch_empty_cache_steps=None,\n",
      "torchdynamo=None,\n",
      "tp_size=0,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_liger_kernel=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.01,\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ce2a73cb-dbfc-49cf-a979-b7bd4fa3863f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2508' max='2508' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2508/2508 07:35, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.103700</td>\n",
       "      <td>0.074490</td>\n",
       "      <td>0.978456</td>\n",
       "      <td>0.993397</td>\n",
       "      <td>0.980449</td>\n",
       "      <td>0.986880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.059500</td>\n",
       "      <td>0.058058</td>\n",
       "      <td>0.983842</td>\n",
       "      <td>0.991292</td>\n",
       "      <td>0.989138</td>\n",
       "      <td>0.990214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>0.066593</td>\n",
       "      <td>0.986236</td>\n",
       "      <td>0.990607</td>\n",
       "      <td>0.992759</td>\n",
       "      <td>0.991682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2508, training_loss=0.06900701458837712, metrics={'train_runtime': 459.4056, 'train_samples_per_second': 87.295, 'train_steps_per_second': 5.459, 'total_flos': 1318975720519680.0, 'train_loss': 0.06900701458837712, 'epoch': 3.0})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5ae69b6d-a99c-4d5a-a9a2-53a647936edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27/27 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07970614731311798, 'eval_accuracy': 0.9856459330143541, 'eval_precision': 0.9913169319826338, 'eval_recall': 0.9913169319826338, 'eval_f1': 0.9913169319826338, 'eval_runtime': 4.869, 'eval_samples_per_second': 343.397, 'eval_steps_per_second': 5.545, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "test_metrics = trainer.evaluate(tokenized_dataset[\"test\"])\n",
    "print(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "63785755-f187-4cb7-9fac-9c3d4af273c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./notebooks/results/checkpoint-2508/tokenizer_config.json',\n",
       " './notebooks/results/checkpoint-2508/special_tokens_map.json',\n",
       " './notebooks/results/checkpoint-2508/vocab.txt',\n",
       " './notebooks/results/checkpoint-2508/added_tokens.json')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"./notebooks/results/checkpoint-2508\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1a4795f9-20a9-47d3-a0f3-031b76d2a377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tokenizer_config.json', 'special_tokens_map.json', 'vocab.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "tokenizer_path = \"./notebooks/results/checkpoint-2508\"\n",
    "print(os.listdir(tokenizer_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0d09f669-dbfe-4681-a0d2-60db804bd946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned name: fashion book for kids\n",
      "Prediction: Fashion (Confidence: 0.9594)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Ambiguous product\n",
    "custom_name = \"fashion book for kids\"\n",
    "\n",
    "# Clean the name\n",
    "def clean_product_name(text):\n",
    "    import re\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z0-9\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "cleaned_name = clean_product_name(custom_name)\n",
    "print(f\"Cleaned name: {cleaned_name}\")\n",
    "\n",
    "# Tokenize and send to CPU\n",
    "encoded_input = tokenizer(\n",
    "    cleaned_name,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=64,\n",
    "    return_tensors=\"pt\"\n",
    ").to(\"cpu\")\n",
    "\n",
    "# Move model to CPU\n",
    "model.to(\"cpu\")\n",
    "\n",
    "# Predict\n",
    "with torch.no_grad():\n",
    "    output = model(**encoded_input)\n",
    "    predicted_class = torch.argmax(output.logits).item()\n",
    "\n",
    "# Get confidence\n",
    "probs = F.softmax(output.logits, dim=1)\n",
    "confidence = probs[0][predicted_class].item()\n",
    "\n",
    "label_map = {0: \"Not Fashion\", 1: \"Fashion\"}\n",
    "print(f\"Prediction: {label_map[predicted_class]} (Confidence: {confidence:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1278d3-7578-4b08-a1d0-4d91d4c3e402",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bert_env)",
   "language": "python",
   "name": "bert_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
